{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(2019)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras import metrics\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 images belonging to 2 classes.\n",
      "Found 140 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"/home/dai/Downloads/my project/Brain Tumor Images Dataset-20200103T163459Z-001/Brain Tumor Images Dataset/training_set\"\n",
    "validation_dir = \"/home/dai/Downloads/my project/Brain Tumor Images Dataset-20200103T163459Z-001/Brain Tumor Images Dataset/training_set/\"\n",
    "\n",
    "# All images will be rescaled by 1./255.\n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=20,\n",
    "                                                    class_mode='binary',\n",
    "                                                    target_size=(150, 150))     \n",
    "# --------------------\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "# --------------------\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size=20,\n",
    "                                                         class_mode  = 'binary',\n",
    "                                                         target_size = (150, 150))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2), \n",
    "    \n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(), \n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'), \n",
    "    tf.keras.layers.Dropout(0.1, seed=2019),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2, seed=2019),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('Organic') \n",
    "    # and 1 for the other ('Recycled')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 148, 148, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 72, 72, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 36, 36, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 34, 34, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 17, 17, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 15, 15, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 512,129\n",
      "Trainable params: 512,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 9s 929ms/step - loss: 0.6956 - accuracy: 0.5500 - val_loss: 0.6619 - val_accuracy: 0.5580\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 9s 918ms/step - loss: 0.6518 - accuracy: 0.6150 - val_loss: 0.5283 - val_accuracy: 0.7460\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 9s 917ms/step - loss: 0.4550 - accuracy: 0.7650 - val_loss: 0.4465 - val_accuracy: 0.7450\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 9s 898ms/step - loss: 0.4635 - accuracy: 0.7650 - val_loss: 0.2888 - val_accuracy: 0.8920\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 9s 917ms/step - loss: 0.4031 - accuracy: 0.8100 - val_loss: 0.2726 - val_accuracy: 0.9150\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 9s 900ms/step - loss: 0.3092 - accuracy: 0.8800 - val_loss: 0.2099 - val_accuracy: 0.9230\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 9s 907ms/step - loss: 0.2363 - accuracy: 0.8900 - val_loss: 0.2475 - val_accuracy: 0.8940\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 9s 913ms/step - loss: 0.2277 - accuracy: 0.9150 - val_loss: 0.1286 - val_accuracy: 0.9710\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 9s 910ms/step - loss: 0.2097 - accuracy: 0.9350 - val_loss: 0.1291 - val_accuracy: 0.9640\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 9s 910ms/step - loss: 0.2184 - accuracy: 0.9000 - val_loss: 0.1011 - val_accuracy: 0.9650\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data=validation_generator,\n",
    "                              steps_per_epoch=10,\n",
    "                              epochs=10,\n",
    "                              validation_steps=50,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_new.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "1.It is cancer\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('model_new.h5')\n",
    "model.compile(loss='binary_crossentropy',\n",
    "\n",
    "              optimizer='rmsprop',\n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "img = cv2.imread('/home/dai/Downloads/my project/Brain Tumor Images Dataset-20200103T163459Z-001/Brain Tumor Images Dataset/test_set/hemmorhage_data/028.png')\n",
    "img = cv2.resize(img,(150,150))\n",
    "img = np.reshape(img,[1,150,150,3])\n",
    "img = tf.cast(img, tf.float32)\n",
    "classes = model.predict_classes(img)\n",
    "print(classes)\n",
    "i = 1\n",
    "\n",
    "for things in classes:  \n",
    "    if(things == 0):\n",
    "        print('%d.It is cancer'%(i))\n",
    "    else:\n",
    "        print('%d.Not cancer'%(i))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "1.Not cancer\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('model_new.h5')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "\n",
    "              optimizer='rmsprop',\n",
    "\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "img = cv2.imread('/home/dai/Downloads/my project/Brain Tumor Images Dataset-20200103T163459Z-001/Brain Tumor Images Dataset/test_set/non_hemmorhage_data/128.png')\n",
    "img = cv2.resize(img,(150,150))\n",
    "img = np.reshape(img,[1,150,150,3])\n",
    "img = tf.cast(img, tf.float32)\n",
    "classes = model.predict_classes(img)\n",
    "print(classes)\n",
    "i = 1\n",
    "\n",
    "for things in classes:  \n",
    "    if(things == 0):\n",
    "        print('%d.It is cancer'%(i))\n",
    "    else:\n",
    "        print('%d.Not cancer'%(i))\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
